{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d066978e",
   "metadata": {},
   "source": [
    "<b>1. What is feature engineering, and how does it work? Explain the various aspects of feature\n",
    "engineering in depth.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38af5b",
   "metadata": {},
   "source": [
    "Ans: The features in your data will directly influence the predictive models you use and the results you can achieve.\n",
    "\n",
    "You can say that: the better the features that you prepare and choose, the better the results you will achieve. It is true, but it also misleading.\n",
    "\n",
    "The results you achieve are a factor of the model you choose, the data you have available and the features you prepared. Even your framing of the problem and objective measures you’re using to estimate accuracy play a part. Your results are dependent on many inter-dependent properties.\n",
    "\n",
    "You need great features that describe the structures inherent in your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5078b",
   "metadata": {},
   "source": [
    "<b>2. What is feature selection, and how does it work? What is the aim of it? What are the various\n",
    "methods of function selection?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f617119",
   "metadata": {},
   "source": [
    "Ans: \n",
    "Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the \n",
    "target variable. Feature selection is primarily focused on removing non-informative or redundant predictors from the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48a205",
   "metadata": {},
   "source": [
    "<b>3. Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
    "approach?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141b85b",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "filter based methods use some mathematical evaluation function (that are based on the intrinsic characteristic of the training set like correlation or recently the Mutual information).\n",
    "however the wrapper methods use a classification perfromance of an classifier (like accuracy ) to do the evaluation.\n",
    "wrapper based are advantageous for giving better performances since they use the  target classifier the feature selection algorithm but they suffer from being computaionnaly expensive.\n",
    "When we compare the filter to the wrapper methods, filter methods are less accurate but faster to compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23486b",
   "metadata": {},
   "source": [
    "<b>4.i. Describe the overall feature selection process.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de275d77",
   "metadata": {},
   "source": [
    "Ans:  feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant\n",
    " features (variables, predictors) for use in model construction. Feature selection techniques are used for several reasons:\n",
    "\n",
    "ii. Explain the key underlying principle of feature extraction using an example. What are the most\n",
    "widely used function extraction algorithms?\n",
    "ANs: Feature extraction is a part of the dimensionality reduction process, in which, an initial set of the raw data is divided and reduced to more manageable groups. So when you want to process it will be easier. The most important characteristic of these large data sets is that they have a large number of variables. These variables require a lot of computing resources to process them. So Feature extraction helps to get the best feature from those big data sets by select and combine variables into features, thus, effectively reducing the amount of data.\n",
    " These features are easy to process, but still able to describe the actual data set with the accuracy and originality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6b546",
   "metadata": {},
   "source": [
    "<b>5. Describe the feature engineering process in the sense of a text categorization issue.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c9cfa",
   "metadata": {},
   "source": [
    "Ans: \n",
    "Feature engineering is one of the most important steps in machine learning. It is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Think machine learning algorithm as a learning child the more accurate information you provide the more they will be able to interpret the information well. Focusing first on our data will give us better results than focusing only on models. Feature engineering helps us to create better data which helps the model understand it well and provide reasonable results.\n",
    "\n",
    "NLP is a subfield of artificial intelligence where we understand human interaction with machines using natural languages. To understand a natural language, you need to understand how we write a sentence, how we express our thoughts using different words, signs, special characters, etc basically we should understand the context of the sentence to interpret its meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9caaa6d",
   "metadata": {},
   "source": [
    "<b>6. What makes cosine similarity a good metric for text categorization? A document-term matrix has\n",
    "two rows with values of (2, 3, 2, 0, 2, 3, 3, 0, 1) and (2, 1, 0, 0, 3, 2, 1, 3, 1). Find the resemblance in\n",
    "cosine.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19773e07",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5a4cb",
   "metadata": {},
   "source": [
    "<b>7.i. What is the formula for calculating Hamming distance? Between 10001011 and 11001111,\n",
    "calculate the Hamming gap.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a33b1c",
   "metadata": {},
   "source": [
    "Ans: \n",
    "In simple scenarios, calculating Hamming distance is easy, though it's important to remember that Hamming distance can only be calculated for lines that are the same length. You simply add up the number of spots where the lines have different values. In the example above, the Hamming distance would be three, since the lines have different values in three spots. Making this comparison becomes more time-consuming the longer the line of binary code is, however. Consider a slightly longer example, with two lines of code: 100110 and 110011. These lines of code both contain six information points. The values are different in three of those points, so the Hamming distance between these two lines is also three. Calculating Hamming\n",
    "distance with a larger set of data becomes more complicated and involves using intricate equations and functions like d=min {d(x,y):x,y∈C,x≠y}.\n",
    "\n",
    "ii. Compare the Jaccard index and similarity matching coefficient of two features with values (1, 1, 0,\n",
    "0, 1, 0, 1, 1) and (1, 1, 0, 0, 0, 1, 1, 1), respectively (1, 0, 0, 1, 1, 0, 0, 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6af52",
   "metadata": {},
   "source": [
    "<b>8. State what is meant by &quot;high-dimensional data set&quot;? Could you offer a few real-life examples?\n",
    "What are the difficulties in using machine learning techniques on a data set with many dimensions?\n",
    "What can be done about it?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541c2d4",
   "metadata": {},
   "source": [
    "Ans: Curse of Dimensionality refers to a set of problems that arise when working with high-dimensional data. The dimension of a dataset corresponds to the number of attributes/features that exist in a dataset. A dataset with a large number of attributes, generally of the order of a hundred or more, is referred to as high dimensional data. Some of the difficulties that come with high dimensional data manifest during analyzing or visualizing the data to identify patterns, and some manifest while training machine learning models. The difficulties related to training machine learning models due to high dimensional data is referred to as ‘Curse of Dimensionality’. \n",
    "The popular aspects of the curse of dimensionality; ‘data sparsity’ and ‘distance concentration’ are discussed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e301af",
   "metadata": {},
   "source": [
    "<b>9. Make a few quick notes on:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cdc67f",
   "metadata": {},
   "source": [
    "1.PCA is an acronym for Personal Computer Analysis.\n",
    "Ans: Principal component analysis (PCA) is a technique used for identification of a smaller number of uncorrelated variables known as \n",
    "principal components from a larger set of data. The technique is widely used to emphasize variation and capture strong patterns in a data set.\n",
    "\n",
    "2. Use of vectors\n",
    "Ans:Vectors can be used to represent physical quantities. Most commonly in physics, vectors are used to represent displacement, velocity, and acceleration. Vectors are a combination of magnitude and direction, and are drawn as arrows.\n",
    " \n",
    "3. Embedded technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5355ffa",
   "metadata": {},
   "source": [
    "<b>10. Make a comparison between:\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc247a1b",
   "metadata": {},
   "source": [
    "1. Sequential backward exclusion vs. sequential forward selection\n",
    "ANs: Sequential floating forward selection (SFFS) starts from the empty set. After each forward step, SFFS performs backward steps as long as the objective function increases. Sequential floating backward selection (SFBS) starts from the full set.\n",
    "\n",
    "\n",
    "2. Function selection methods: filter vs. wrapper\n",
    "Ans: The main differences between the filter and wrapper methods for feature selection are: Filter methods measure the relevance of features by their correlation with dependent\n",
    "variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it\n",
    "\n",
    "3. SMC vs. Jaccard coefficient\n",
    "Ans: The simple matching coefficient (SMC) or Rand similarity coefficient is a statistic used for ... The SMC is very similar to the more popular Jaccard index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b986cc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05772eff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050f2ffd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8e1d7aa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
